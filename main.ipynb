{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/proffranciscofernando/house_price_prediction/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZEQogo9zyjn"
      },
      "source": [
        "# California House Price Prediction\n",
        "\n",
        "This notebook demonstrates a machine learning pipeline built with Scikit-Learn to predict house prices in California. It includes data preprocessing, model training, hyperparameter optimisation using Grid Search with cross-validation, and an interactive interface for making predictions based on user input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q387UPn7zyjq"
      },
      "source": [
        "## 1. Importing Necessary Libraries\n",
        "\n",
        "Firstly, we import all the necessary libraries and suppress any non-critical warnings for cleaner output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HxD_vWSzyjq"
      },
      "outputs": [],
      "source": [
        "# Importing Necessary Libraries and Suppressing Warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "import joblib  # For saving and loading the model\n",
        "\n",
        "# Suppressing warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRDTuVyIzyjs"
      },
      "source": [
        "## 2. Loading and Exploring the Dataset\n",
        "\n",
        "We will use the **California Housing Dataset** to predict house prices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX6-iMftzyjs"
      },
      "source": [
        "### 2.1 Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdsTTik8zyjs"
      },
      "outputs": [],
      "source": [
        "# Loading the dataset\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "data = fetch_california_housing(as_frame=True)\n",
        "df = data.frame\n",
        "\n",
        "# Viewing the first few rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltkz5hDgzyjt"
      },
      "source": [
        "### 2.2 Exploratory Data Analysis\n",
        "\n",
        "Let's check the basic information of the dataset to understand its structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QHXczUdzyjt"
      },
      "outputs": [],
      "source": [
        "# Basic information about the dataset\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARhHzbltzyjt"
      },
      "source": [
        "### 2.3 Selecting Features and Target Variable\n",
        "\n",
        "We will select some relevant columns to simplify the example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_E1c5vTzyju"
      },
      "outputs": [],
      "source": [
        "# Selecting features and target variable\n",
        "X = df.drop('MedHouseVal', axis=1)\n",
        "y = df['MedHouseVal']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rVSp6mqzyju"
      },
      "source": [
        "### 2.4 Handling Missing Values\n",
        "\n",
        "We will check for any missing values in the selected data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lU3S9Op0zyju"
      },
      "outputs": [],
      "source": [
        "# Checking for missing values\n",
        "X.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFTI2R16zyju"
      },
      "source": [
        "As we can see, there are no missing values in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU0YxL8Kzyju"
      },
      "source": [
        "## 3. Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0hAh54Ezyjv"
      },
      "source": [
        "### 3.1 Splitting Data into Training and Testing Sets\n",
        "\n",
        "We split the dataset into training and testing sets to evaluate the performance of the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaL3ORRezyjv"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coj1b_4Rzyjv"
      },
      "source": [
        "## 4. Building the Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyRlC7NOzyjv"
      },
      "source": [
        "### 4.1 Creating the Preprocessing Pipeline\n",
        "\n",
        "We define transformations for numerical columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9oqnjPSzyjv"
      },
      "outputs": [],
      "source": [
        "# Defining numerical columns (there are no categorical columns in this dataset)\n",
        "numeric_features = X.columns.tolist()\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Since we have no categorical features, we do not define a categorical transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjFBseitzyjv"
      },
      "source": [
        "## 5. Hyperparameter Optimisation with Grid Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zUCW60wzyjv"
      },
      "source": [
        "### 5.1 Defining Models and Parameters\n",
        "\n",
        "We will define a list of regression models and the hyperparameters we wish to optimise for each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdJQUh93zyjv"
      },
      "outputs": [],
      "source": [
        "# Defining models and their hyperparameters\n",
        "models_params = {\n",
        "    'Linear Regression': {\n",
        "        'model': LinearRegression(),\n",
        "        'params': {}\n",
        "    },\n",
        "    'Ridge Regression': {\n",
        "        'model': Ridge(),\n",
        "        'params': {\n",
        "            'regressor__alpha': [0.1, 1.0, 10.0]\n",
        "        }\n",
        "    },\n",
        "    'Lasso Regression': {\n",
        "        'model': Lasso(),\n",
        "        'params': {\n",
        "            'regressor__alpha': [0.001, 0.01, 0.1, 1.0]\n",
        "        }\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'model': RandomForestRegressor(),\n",
        "        'params': {\n",
        "            'regressor__n_estimators': [50, 100, 200],\n",
        "            'regressor__max_depth': [None, 5, 10]\n",
        "        }\n",
        "    },\n",
        "    'SVR': {\n",
        "        'model': SVR(),\n",
        "        'params': {\n",
        "            'regressor__C': [0.1, 1, 10],\n",
        "            'regressor__kernel': ['linear', 'rbf']\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeynGTjqzyjw"
      },
      "source": [
        "### 5.2 Running Grid Search with Cross-Validation\n",
        "\n",
        "Now, we will perform Grid Search with cross-validation for each model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-05T10:15:00.000000Z",
          "iopub.execute_input": "2021-10-05T10:15:00.000000Z",
          "iopub.status.idle": "2021-10-05T10:15:00.000000Z",
          "shell.execute_reply": "2021-10-05T10:15:00.000000Z"
        },
        "id": "dlEEBH1tzyjw"
      },
      "outputs": [],
      "source": [
        "# Running Grid Search with cross-validation for each model\n",
        "results = []\n",
        "\n",
        "for name, mp in models_params.items():\n",
        "    model = mp['model']\n",
        "    params = mp.get('params', {})\n",
        "\n",
        "    # Creating the pipeline with the current model\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', model)\n",
        "    ])\n",
        "\n",
        "    if params:\n",
        "        # Grid Search with cross-validation\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=pipeline,\n",
        "            param_grid=params,\n",
        "            cv=5,\n",
        "            scoring='neg_mean_squared_error',\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "        # Training the model\n",
        "        grid_search.fit(X_train, y_train)\n",
        "\n",
        "        # Best model found\n",
        "        best_model = grid_search.best_estimator_\n",
        "    else:\n",
        "        # If there are no hyperparameters to tune\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        best_model = pipeline\n",
        "        grid_search = None\n",
        "\n",
        "    # Making predictions on the test set\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Calculating metrics\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Storing the results\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Best Hyperparameters': grid_search.best_params_ if params else 'N/A',\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'R²': r2,\n",
        "        'Pipeline': best_model  # Storing the best model\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF5jVLd-zyjw"
      },
      "source": [
        "### 5.3 Comparing Optimised Models\n",
        "\n",
        "Let's visualise the metrics of each optimised model in a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-05T10:16:00.000000Z",
          "iopub.execute_input": "2021-10-05T10:16:00.000000Z",
          "iopub.status.idle": "2021-10-05T10:16:00.000000Z",
          "shell.execute_reply": "2021-10-05T10:16:00.000000Z"
        },
        "id": "5NHifGu8zyjw"
      },
      "outputs": [],
      "source": [
        "# Comparing the optimised models\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results = df_results.sort_values(by='RMSE')\n",
        "df_results.reset_index(drop=True, inplace=True)\n",
        "df_results[['Model', 'MAE', 'RMSE', 'R²', 'Best Hyperparameters']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0S_BqZCzyjx"
      },
      "source": [
        "## 6. Selecting and Saving the Best Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C-_rygbzyjx"
      },
      "source": [
        "### 6.1 Selecting the Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-05T10:17:00.000000Z",
          "iopub.execute_input": "2021-10-05T10:17:00.000000Z",
          "iopub.status.idle": "2021-10-05T10:17:00.000000Z",
          "shell.execute_reply": "2021-10-05T10:17:00.000000Z"
        },
        "id": "RjLi_A29zyjx"
      },
      "outputs": [],
      "source": [
        "# Selecting the best model based on RMSE\n",
        "best_model_name = df_results.loc[0, 'Model']\n",
        "best_pipeline = df_results.loc[0, 'Pipeline']\n",
        "\n",
        "print(f\"The best model was: {best_model_name}\")\n",
        "print(f\"With hyperparameters: {df_results.loc[0, 'Best Hyperparameters']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6Kj1PdLzyjx"
      },
      "source": [
        "### 6.2 Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-05T10:18:00.000000Z",
          "iopub.execute_input": "2021-10-05T10:18:00.000000Z",
          "iopub.status.idle": "2021-10-05T10:18:00.000000Z",
          "shell.execute_reply": "2021-10-05T10:18:00.000000Z"
        },
        "id": "ZIT04NTkzyjx"
      },
      "outputs": [],
      "source": [
        "# Saving the model using joblib\n",
        "joblib.dump(best_pipeline, 'best_model.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS5n2-SJzyjx"
      },
      "source": [
        "## 7. Loading the Model and Making Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNhluENdzyjx"
      },
      "source": [
        "### 7.1 Making Predictions with New User Input\n",
        "\n",
        "In this section, we will create an interactive interface where the user can input new data, and the model will make predictions based on that data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-05T10:19:00.000000Z",
          "iopub.execute_input": "2021-10-05T10:19:00.000000Z",
          "iopub.status.idle": "2021-10-05T10:19:00.000000Z",
          "shell.execute_reply": "2021-10-05T10:19:00.000000Z"
        },
        "id": "d5Cb4IFqzyjx"
      },
      "outputs": [],
      "source": [
        "# Loading the saved model\n",
        "loaded_model = joblib.load('best_model.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed1dbD0Yzyjy"
      },
      "source": [
        "#### Function to Get User Input Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-05T10:20:00.000000Z",
          "iopub.execute_input": "2021-10-05T10:20:00.000000Z",
          "iopub.status.idle": "2021-10-05T10:20:00.000000Z",
          "shell.execute_reply": "2021-10-05T10:20:00.000000Z"
        },
        "id": "O5cKwzYPzyjy"
      },
      "outputs": [],
      "source": [
        "# Function to get user input data\n",
        "def get_user_data():\n",
        "    print(\"Please enter the house details:\")\n",
        "\n",
        "    # Prompting user for input\n",
        "    MedInc = input(\"MedInc (Median income in tens of thousands): \")\n",
        "    while True:\n",
        "        try:\n",
        "            MedInc = float(MedInc)\n",
        "            if MedInc < 0:\n",
        "                raise ValueError\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Invalid value. Please enter a positive number.\")\n",
        "            MedInc = input(\"MedInc: \")\n",
        "\n",
        "    HouseAge = input(\"HouseAge (Median house age in the area): \")\n",
        "    while True:\n",
        "        try:\n",
        "            HouseAge = float(HouseAge)\n",
        "            if HouseAge < 0:\n",
        "                raise ValueError\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Invalid value. Please enter a positive number.\")\n",
        "            HouseAge = input(\"HouseAge: \")\n",
        "\n",
        "    AveRooms = input(\"AveRooms (Average rooms per house): \")\n",
        "    while True:\n",
        "        try:\n",
        "            AveRooms = float(AveRooms)\n",
        "            if AveRooms <= 0:\n",
        "                raise ValueError\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Invalid value. Please enter a positive number.\")\n",
        "            AveRooms = input(\"AveRooms: \")\n",
        "\n",
        "    AveBedrms = input(\"AveBedrms (Average bedrooms per house): \")\n",
        "    while True:\n",
        "        try:\n",
        "            AveBedrms = float(AveBedrms)\n",
        "            if AveBedrms <= 0:\n",
        "                raise ValueError\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Invalid value. Please enter a positive number.\")\n",
        "            AveBedrms = input(\"AveBedrms: \")\n",
        "\n",
        "    Population = input(\"Population (Population of the block): \")\n",
        "    while True:\n",
        "        try:\n",
        "            Population = float(Population)\n",
        "            if Population <= 0:\n",
        "                raise ValueError\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Invalid value. Please enter a positive number.\")\n",
        "            Population = input(\"Population: \")\n",
        "\n",
        "    AveOccup = input(\"AveOccup (Average occupancy per house): \")\n",
        "    while True:\n",
        "        try:\n",
        "            AveOccup = float(AveOccup)\n",
        "            if AveOccup <= 0:\n",
        "                raise ValueError\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Invalid value. Please enter a positive number.\")\n",
        "            AveOccup = input(\"AveOccup: \")\n",
        "\n",
        "    Latitude = input(\"Latitude: \")\n",
        "    while True:\n",
        "        try:\n",
        "            Latitude = float(Latitude)\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Invalid value. Please enter a number.\")\n",
        "            Latitude = input(\"Latitude: \")\n",
        "\n",
        "    Longitude = input(\"Longitude: \")\n",
        "    while True:\n",
        "        try:\n",
        "            Longitude = float(Longitude)\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Invalid value. Please enter a number.\")\n",
        "            Longitude = input(\"Longitude: \")\n",
        "\n",
        "    # Creating a DataFrame with the entered data\n",
        "    new_house = pd.DataFrame({\n",
        "        'MedInc': [MedInc],\n",
        "        'HouseAge': [HouseAge],\n",
        "        'AveRooms': [AveRooms],\n",
        "        'AveBedrms': [AveBedrms],\n",
        "        'Population': [Population],\n",
        "        'AveOccup': [AveOccup],\n",
        "        'Latitude': [Latitude],\n",
        "        'Longitude': [Longitude]\n",
        "    })\n",
        "\n",
        "    return new_house"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65S8qsMdzyjy"
      },
      "source": [
        "#### Iterative Loop for Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-05T10:21:00.000000Z",
          "iopub.execute_input": "2021-10-05T10:21:00.000000Z",
          "iopub.status.idle": "2021-10-05T10:21:00.000000Z",
          "shell.execute_reply": "2021-10-05T10:21:00.000000Z"
        },
        "id": "vnmTfFmfzyjy"
      },
      "outputs": [],
      "source": [
        "# Iterative loop for making predictions\n",
        "while True:\n",
        "    # Get user input data\n",
        "    new_house = get_user_data()\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = loaded_model.predict(new_house)\n",
        "\n",
        "    predicted_price = prediction[0]\n",
        "\n",
        "    print(f\"\\nPredicted house price: ${predicted_price * 100000:.2f}\\n\")\n",
        "\n",
        "    # Ask if the user wants to input another house\n",
        "    continue_input = input(\"Would you like to enter another house? (y/n): \").lower()\n",
        "    if continue_input != 'y':\n",
        "        print(\"Ending predictions.\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obcxQLsvzyjy"
      },
      "source": [
        "## 8. Conclusion\n",
        "\n",
        "In this notebook, we built a machine learning pipeline that includes multiple regression models. We utilised Grid Search with cross-validation to optimise the hyperparameters of each model. We evaluated each model using metrics such as MAE, RMSE, and R². Based on these metrics, we selected the best optimised model and saved it for future use. Finally, we implemented an interactive interface that allows users to input new data and obtain model predictions, making the application practical and interactive.\n",
        "\n",
        "This process is essential in machine learning projects to ensure that we are selecting the most appropriate model and hyperparameters for our problem, as well as facilitating the deployment and continuous use of the model in real-world environments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr0I6nZNzyj2"
      },
      "source": [
        "## 9. References\n",
        "\n",
        "- [Scikit-Learn Documentation on Pipelines](https://scikit-learn.org/stable/modules/compose.html#pipeline)\n",
        "- [Scikit-Learn Documentation on GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
        "- [Saving Models with Joblib](https://scikit-learn.org/stable/modules/model_persistence.html)\n",
        "- [California Housing Dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset)\n",
        "- [Cross-Validation in Scikit-Learn](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
        "- [Regression Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}